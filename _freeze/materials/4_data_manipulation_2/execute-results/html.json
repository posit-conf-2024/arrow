{
  "hash": "a3a4b6eb34b2abadf1b7fc69eba9995d",
  "result": {
    "engine": "knitr",
    "markdown": "---\nfooter: \"[🔗 pos.it/arrow-conf24](https://pos.it/arrow-conf24)\"\nlogo: \"images/logo.png\"\nexecute:\n  echo: true\nformat:\n  revealjs: \n    theme: default\nengine: knitr\neditor: source\n---\n\n\n\n\n# Data Manipulation---Part 2 {#data-manip-2}\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n## What if a function binding doesn't exist - revisited!\n\n-   Option 1 - find a workaround\n-   Option 2 - user-defined functions (UDFs)\n\n## Why use a UDF?\n\n* If no bindings for a function exist\n* Implement your own custom functions\n* Run in R not Arrow\n\n<!-- \nIn arrow 17.0.0 there will be less need to do this for custom functions\n\n-->\n\n## How do function bindings usually work?\n\n![](images/udf_normal.png)\n\n## How do UDFs work?\n\n![](images/udf.png)\n\n## A function\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntime_diff_minutes <- function(pickup, dropoff){\n  difftime(dropoff, pickup, units = \"mins\") |>\n      round() |>\n      as.integer()\n}\n\nnyc_taxi |>\n  mutate(\n    duration_minutes = time_diff_minutes(pickup_datetime, dropoff_datetime)\n  ) |> \n  select(pickup_datetime, dropoff_datetime, duration_minutes) |>\n  head() |>\n  collect()\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in `time_diff_minutes()`:\n! `difftime()` with units other than `secs` not supported in Arrow\n→ Call collect() first to pull data into R.\n```\n\n\n:::\n:::\n\n\n\nWe get an error as we can't automatically convert the function to arrow.\n\n<!-- \n* why did this happen?\n* Look at ?acero and show how difftime is implemented but only supports units= \"secs\"\n\n-->\n\n# User-defined functions (aka UDFs)\n\n-   Define your own functions\n-   Scalar functions - 1 row input and 1 row output\n\n<!-- \n* Instead of having an Acero binding, Acero calls back to R to work out the result\n* Naturally slower than working entirely in Acero as now we don't have vectorisation, or any of the Arrow C++ optimisations\n* But, ultimately makes it possible\n-->\n\n## User-defined functions - definition\n\n<!-- \nshow slide don't type\n-->\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nregister_scalar_function(\n  name = \"time_diff_minutes\",\n  function(context, pickup, dropoff) {\n    difftime(dropoff, pickup, units = \"mins\") |>\n      round() |>\n      as.integer()\n  },\n  in_type = schema(\n    pickup = timestamp(unit = \"ms\"),\n    dropoff = timestamp(unit = \"ms\")\n  ),\n  out_type = int32(),\n  auto_convert = TRUE\n)\n```\n:::\n\n\n\n\nThis looks complicated, so let's look at it 1 part at a time!\n\n<!-- \nUDFs *are* ugly!\nAnd that's because when we have bindings, we rely on the arrow R package's internals to handle all the complicated stuff like working out the types of the values.\nBut it's not as bad as it looks, so we'll break it down!\n\n-->\n\n## User-defined functions - definition\n\nStep 1. Give the function a name\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"2\"}\nregister_scalar_function(\n  name = \"time_diff_minutes\",\n  function(context, pickup, dropoff) {\n    difftime(dropoff, pickup, units = \"mins\") |>\n      round() |>\n      as.integer()\n  },\n  in_type = schema(\n    pickup = timestamp(unit = \"ms\"),\n    dropoff = timestamp(unit = \"ms\")\n  ),\n  out_type = int32(),\n  auto_convert = TRUE\n)\n```\n:::\n\n\n\n\n<!--\nshow ?register_scalar_function help file\n\nset up the skeleton (i.e. register_scalar_function) and add in components 1 at a time\n\nname = some name to call it\n\nfun = the body of the function. first argument must be called \"context\" and you don't do anything with it - it'll be used by Acero to pass some metadata between Arrow and R. after that, define other arguments, and the function body like you otherwise would.\n\nin_type and out_type = so usually we don't have to worry about data types as the bindings do that for us, but now we're working more closely with Acero's internals, we need to do more things manually, so we have to tell it the data type of the input and output columns\n\nThe `auto_convert` argument controls whether arrow automatically converts the inputs to R vectors or not.\nThe default value `FALSE` can be used when working with R6 objects, but as we're working in an arrow dplyr pipeline here, we'll set it to `TRUE`.\n-->\n\n## User-defined functions - definition\n\nStep 2. Define the body of the function - first argument *must* be `context`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"3,4,5,6,7\"}\nregister_scalar_function(\n  name = \"time_diff_minutes\",\n  function(context, pickup, dropoff) {\n    difftime(dropoff, pickup, units = \"mins\") |>\n      round() |>\n      as.integer()\n  },\n  in_type = schema(\n    pickup = timestamp(unit = \"ms\"),\n    dropoff = timestamp(unit = \"ms\")\n  ),\n  out_type = int32(),\n  auto_convert = TRUE\n)\n```\n:::\n\n\n\n\n## User-defined functions - definition\n\nStep 3. Set the schema of the input arguments\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"8,9,10,11\"}\nregister_scalar_function(\n  name = \"time_diff_minutes\",\n  function(context, pickup, dropoff) {\n    difftime(dropoff, pickup, units = \"mins\") |>\n      round() |>\n      as.integer()\n  },\n  in_type = schema(\n    pickup = timestamp(unit = \"ms\"),\n    dropoff = timestamp(unit = \"ms\")\n  ),\n  out_type = int32(),\n  auto_convert = TRUE\n)\n```\n:::\n\n\n\n\n## User-defined functions - definition\n\nStep 4. Set the data type of the output\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"12\"}\nregister_scalar_function(\n  name = \"time_diff_minutes\",\n  function(context, pickup, dropoff) {\n    difftime(dropoff, pickup, units = \"mins\") |>\n      round() |>\n      as.integer()\n  },\n  in_type = schema(\n    pickup = timestamp(unit = \"ms\"),\n    dropoff = timestamp(unit = \"ms\")\n  ),\n  out_type = int32(),\n  auto_convert = TRUE\n)\n```\n:::\n\n\n\n\n## User-defined functions - definition\n\nStep 5. Set `auto_convert = TRUE` if using in a dplyr pipeline\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"13\"}\nregister_scalar_function(\n  name = \"time_diff_minutes\",\n  function(context, pickup, dropoff) {\n    difftime(dropoff, pickup, units = \"mins\") |>\n      round() |>\n      as.integer()\n  },\n  in_type = schema(\n    pickup = timestamp(unit = \"ms\"),\n    dropoff = timestamp(unit = \"ms\")\n  ),\n  out_type = int32(),\n  auto_convert = TRUE\n)\n```\n:::\n\n\n\n\n## User-defined functions - usage\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnyc_taxi |>\n  mutate(\n    duration_minutes = time_diff_minutes(pickup_datetime, dropoff_datetime)\n  ) |>\n  select(pickup_datetime, dropoff_datetime, duration_minutes) |>\n  head() |>\n  collect()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  pickup_datetime     dropoff_datetime    duration_minutes\n  <dttm>              <dttm>                         <int>\n1 2012-10-07 10:19:00 2012-10-07 10:29:00               10\n2 2012-10-07 10:19:00 2012-10-07 10:33:00               14\n3 2012-10-07 10:19:00 2012-10-07 10:35:00               16\n4 2012-10-07 10:19:00 2012-10-07 10:35:00               16\n5 2012-10-07 10:19:00 2012-10-07 10:42:00               23\n6 2012-10-07 10:19:00 2012-10-07 10:43:00               24\n```\n\n\n:::\n:::\n\n\n\n\n<!-- \nSo, we call `register_scalar_function()` to create it, and then then when we run our pipeline it appears there\n-->\n\n## Your Turn\n\n1.  Write a user-defined function which wraps the `stringr` function `str_replace_na()`, and use it to replace any `NA` values in the `vendor_name` column with the string \"No vendor\" instead. (Test it on the data from 2019 so you're not pulling everything into memory)\n\n➡️ [Data Manipulation Part II Exercises Page](4_data_manipulation_2-exercises.html)\n\n## Summary\n\n-   You can use UDFs to create your own bindings when they don't exist\n-   UDFs must be scalar (1 row in -\\> 1 row out) and stateless (no knowledge of other rows of data)\n-   Calculations done by R not Arrow, so slower than in-built bindings but still pretty fast\n\n# Joins\n\n## Joins\n\n![](images/joins.png)\n\n<!-- \n* combining data from different sources into a single source\n* fairly common to encounter when we have a dataset and some sort of reference table to combine it with\n* in the example here, we've done what's called a left-join:\n  * take everything from the table on the left\n  * decide which column to use for the join\n    * in this case, join vendor_name in the left table to code in the right table\n  * to do the join, goes through each row in the left table and finds the matching value in the right table, but then also brings the corresponding column (or multiple) from the right table\n* there are different type of joins, but the focus here isn't on joins, but is on what you need to know about doing joins in arrow\n* let's start off by writing out the code to do the join from the example\n-->\n\n## Joining a reference table\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvendors <- tibble::tibble(\n  code = c(\"VTS\", \"CMT\", \"DDS\"),\n  full_name = c(\n    \"Verifone Transportation Systems\",\n    \"Creative Mobile Technologies\",\n    \"Digital Dispatch Systems\"\n  )\n)\n\nnyc_taxi |>\n  left_join(vendors, by = c(\"vendor_name\" = \"code\")) |>\n  select(vendor_name, full_name, pickup_datetime) |>\n  head(3) |>\n  collect()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  vendor_name full_name                    pickup_datetime    \n  <chr>       <chr>                        <dttm>             \n1 CMT         Creative Mobile Technologies 2012-01-18 07:19:18\n2 CMT         Creative Mobile Technologies 2012-01-18 14:01:40\n3 CMT         Creative Mobile Technologies 2012-01-18 10:10:08\n```\n\n\n:::\n:::\n\n\n\n\n<!-- \n* This was pretty straightforward here, and a lot of the time it should just work, but there are some things you should know about\n\n-->\n\n## Traps for the unwary\n\nQuestion: which are the most common borough-to-borough journeys in the dataset?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnyc_taxi_zones <- \n  read_csv_arrow(\"data/taxi_zone_lookup.csv\") |>\n  select(location_id = LocationID,\n         borough = Borough)\n\nnyc_taxi_zones\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 265 × 2\n   location_id borough      \n         <int> <chr>        \n 1           1 EWR          \n 2           2 Queens       \n 3           3 Bronx        \n 4           4 Manhattan    \n 5           5 Staten Island\n 6           6 Staten Island\n 7           7 Queens       \n 8           8 Queens       \n 9           9 Queens       \n10          10 Queens       \n# ℹ 255 more rows\n```\n\n\n:::\n:::\n\n\n\n\n\n<!-- \n* the taxi data contains location IDs for the different pickup locations, but what if we want to be more generic and look at the different boroughs that people travel between?\n* one of the data files is a reference table which maps the location IDs to their Borough, and so we can answer this question by joining the reference table to our dataset\n* let's take a look\n-->\n\n## Why didn't this work?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnyc_taxi |>\n  left_join(nyc_taxi_zones, by = c(\"pickup_location_id\" = \"location_id\")) |>\n  collect()\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in `compute.arrow_dplyr_query()`:\n! Invalid: Incompatible data types for corresponding join field keys: FieldRef.Name(pickup_location_id) of type int64 and FieldRef.Name(location_id) of type int32\n```\n\n\n:::\n:::\n\n\n\n\n<!-- \n* The thing to do here feels like, let's do a join again then\n* it's complaining about data types, so let's look at the schema of both\n-->\n\n## Schema for the `nyc_taxi` Dataset\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nschema(nyc_taxi)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSchema\nvendor_name: string\npickup_datetime: timestamp[ms]\ndropoff_datetime: timestamp[ms]\npassenger_count: int64\ntrip_distance: double\npickup_longitude: double\npickup_latitude: double\nrate_code: string\nstore_and_fwd: string\ndropoff_longitude: double\ndropoff_latitude: double\npayment_type: string\nfare_amount: double\nextra: double\nmta_tax: double\ntip_amount: double\ntolls_amount: double\ntotal_amount: double\nimprovement_surcharge: double\ncongestion_surcharge: double\npickup_location_id: int64\ndropoff_location_id: int64\nyear: int32\nmonth: int32\n```\n\n\n:::\n:::\n\n\n\n<!-- In the original data, pickup_location_id is an int64 -->\n## Schema for the `nyc_taxi_zones` Table\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnyc_taxi_zones_arrow <- arrow_table(nyc_taxi_zones)\nschema(nyc_taxi_zones_arrow)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSchema\nlocation_id: int32\nborough: string\n```\n\n\n:::\n:::\n\n\n\n\n-   `pickup_location_id` is int64 in the `nyc_taxi` table\n-   `location_id` is int32 in the `nyc_taxi_zones` table\n\n<!-- \nWhen we do a join here, the nyc_taxi_zones object we read in was a tibble as we collected it in memory.\nArrow needs 2 Arrow objects to do a join, so behind the scenes, when we do the join, the tibble is converted into an Arrow Table.\nWhen we convert between R and Arrow objects, Arrow automatically does the type conversion for us.\nThat's why here we call `arrow_table()` to see what the type conversion will be, and call schema()\nThe thing to note here is that these are different types - and arrow needs for the join key column to be the same type. So what we need to do is manually specify the schema.\n-->\n\n## Take control of the schema\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnyc_taxi_zones_arrow <- arrow_table(\n  nyc_taxi_zones, \n  schema = schema(location_id = int64(), borough = utf8())\n)\n```\n:::\n\n\n\n\n-   `schema()` takes variable name / types as input\n-   arrow has various \"type\" functions: `int64()`, `utf8()`, `boolean()`, `date32()` etc\n\n<!-- \nThis time we manually convert the data frame into a table and set the schema\nAlternatively, we could specify it when we read the data in\n-->\n\n## Take control of the schema\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnyc_taxi_zones_arrow <- arrow_table(\n  nyc_taxi_zones, \n  schema = schema(location_id = int64(), borough = utf8())\n)\nschema(nyc_taxi_zones_arrow)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSchema\nlocation_id: int64\nborough: string\n```\n\n\n:::\n:::\n\n\n\n\n<!-- \nNow we can see the schema matches so we should be able to run our analysis\nLet's do 1 final thing to answer our borough to borough question!\n-->\n\n## Prepare the auxiliary tables\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npickup <- nyc_taxi_zones_arrow |>\n  select(pickup_location_id = location_id,\n         pickup_borough = borough)\n\ndropoff <- nyc_taxi_zones_arrow |>\n  select(dropoff_location_id = location_id,\n         dropoff_borough = borough)\n```\n:::\n\n\n\n\n-   Join separately for the pickup and dropoff zones\n\n\n## Join and cross-tabulate\n\n<!-- Run the code and recap the section while the timer runs! -->\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tictoc)\n\ntic()\nborough_counts <- nyc_taxi |> \n  left_join(pickup) |>\n  left_join(dropoff) |>\n  count(pickup_borough, dropoff_borough) |>\n  arrange(desc(n)) |>\n  collect()\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n199.58 sec elapsed\n```\n\n\n:::\n:::\n\n\n\n\n<br>\n\n2-3 minutes to join twice and cross-tabulate on non-partition variables, with 1.15 billion rows of data 🙂\n\n## The results\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nborough_counts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 50 × 3\n   pickup_borough dropoff_borough         n\n   <chr>          <chr>               <int>\n 1 <NA>           <NA>            732357953\n 2 Manhattan      Manhattan       351198872\n 3 Queens         Manhattan        14440705\n 4 Manhattan      Queens           13052517\n 5 Manhattan      Brooklyn         11180867\n 6 Queens         Queens            7440356\n 7 Unknown        Unknown           4491811\n 8 Queens         Brooklyn          3662324\n 9 Brooklyn       Brooklyn          3550480\n10 Manhattan      Bronx             2071830\n# ℹ 40 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Your Turn\n\n1.  How many taxi pickups were recorded in 2019 from the three major airports covered by the NYC Taxis data set (JFK, LaGuardia, Newark)? (Hint: you can use `stringr::str_detect()` to help you find pickup zones with the word \"Airport\" in them)\n\n➡️ [Data Manipulation Part II Exercises Page](4_data_manipulation_2-exercises.html)\n\n## Summary\n\n-   You can join Arrow Tables and Datasets to R data frames and Arrow Tables\n-   The Arrow data type of join keys must always match\n\n",
    "supporting": [
      "4_data_manipulation_2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}